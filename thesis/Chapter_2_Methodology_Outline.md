# CHAPTER 2: LITERATURE REVIEW
## Automated Phishing Detection for Frontier AI Inference Systems

<span style="color:red">Chapter 2 analyzes the scholarly and industry literature that frames phishing detection for AI inference endpoints. The review situates the praxis within three intersecting domains: traditional phishing analytics, adversarial security for machine learning, and real-time detection systems with stringent latency constraints. Each section emphasizes peer-reviewed evidence, conference proceedings, and standards publications that inform the proposed methodology.</span>

## 2.1 Overview of Thematic Domains
<span style="color:red">The literature was organized into five thematic clusters derived from the annotated bibliography: (1) rule-based and machine learning approaches to phishing detection, (2) adversarial attacks on AI systems, (3) inference-time monitoring and latency-sensitive security, (4) labeling protocols and governance frameworks, and (5) gap analyses that identify limitations of current defenses. Sources were prioritized if they offered empirical metrics, reproducible datasets, or deployment insights relevant to inference APIs.</span>

## 2.2 Traditional Phishing Detection Research
<span style="color:red">Early phishing research emphasized handcrafted heuristics, examining lexical features such as URL length, suspicious substrings, and domain reputation (Garera et al., 2007). Subsequent studies introduced machine learning models that leveraged decision trees, Support Vector Machines (SVMs), and ensemble classifiers trained on public datasets like PhishTank and Anti-Phishing Working Group (APWG) feeds (Abdelhamid et al., 2014). Recent advances include deep learning techniques—convolutional neural networks and transformer architectures—that process HTML content and screenshots to achieve accuracy above ninety-five percent on benchmark corpora (PhishDecloaker Team, 2024; Koide et al., 2024).</span>

<span style="color:red">Despite high reported accuracy, these systems share two deficiencies when applied to AI inference: their features assume either human-readable web pages or email content, and their latency is often measured in hundreds of milliseconds to seconds. No reviewed study translates phishing indicators into prompt semantics, token distributions, or API session metadata, leaving a functional gap for inference-based attacks.</span>

## 2.3 Security of AI and Machine Learning Systems
<span style="color:red">The adversarial machine learning literature documents the vulnerability of models to inference-time manipulation. Biggio and Roli (2018) categorize evasion, poisoning, and privacy attacks, establishing foundational threat taxonomies. Tramèr et al. (2016) and Carlini et al. (2023) demonstrate model extraction through query-based black-box probing, where carefully crafted inputs reveal decision boundaries or training data. Perez and Ribeiro (2022) describe prompt injection strategies that reprogram LLM outputs by embedding malicious instructions.</span>

<span style="color:red">These works lend empirical weight to fears that inference APIs can be exploited for phishing-like objectives, including credential harvesting and intellectual property theft. However, most propose defenses centered on architectural modifications to models (e.g., adversarial training) or rate limiting, rather than inference-layer detectors capable of classifying malicious requests in real time. This gap underscores the necessity for feature engineering attentive to AI-specific behaviors.</span>

## 2.4 Latency-Aware Detection and Streaming Analytics
<span style="color:red">Operational deployments require detection systems that add minimal overhead to inference pipelines. Google’s latency studies suggest that users perceive delays beyond two hundred milliseconds as service degradation (Brutlag, 2009). Security literature on streaming analytics offers architectures that process data in micro-batches or event streams to meet sub-second requirements (Liu et al., 2019). In phishing contexts, PhishDecloaker demonstrates sub-two-hundred-millisecond performance for CAPTCHA-cloaked website detection by precomputing visual signatures, while KnowPhish accepts higher latencies to incorporate language-model reasoning.</span>

<span style="color:red">No existing work explicitly benchmarks latency for API-oriented phishing detection, leaving practitioners to extrapolate from web scenarios. This praxis leverages findings from stream processing and edge computing to justify the ensemble design described in Chapter 3, ensuring that the detection layer remains compatible with fast inference Service Level Objectives (SLOs).</span>

## 2.5 Labeling Protocols and Governance Frameworks
<span style="color:red">Accurate labeling is a prerequisite for supervised detection. OpenAI’s usage policies (2024) enumerate prohibited behaviors—including attempts to extract model parameters, generate harmful content, or bypass safety filters—that map directly onto phishing objectives. The NIST AI Risk Management Framework (2023) and MITRE’s Adversarial Threat Landscape for Artificial-Intelligence Systems (ATLAS, 2023) provide taxonomies and control recommendations for categorizing adversarial behaviors.</span>

<span style="color:red">Adapting these frameworks, the praxis defines labeling criteria in which a request is classified as phishing if it: (1) seeks unauthorized access to model configuration or training data, (2) attempts to exhaust inference resources for financial harm, (3) injects instructions that subvert safety policies, or (4) orchestrates coordinated campaigns to manipulate model outputs. Legitimate requests comply with published usage policies and exhibit expected token and rate characteristics. This alignment with established protocols satisfies advisor guidance to avoid bespoke labeling schemes while maintaining academic rigor.</span>

## 2.6 Gap Analysis
<span style="color:red">Synthesizing the literature reveals four unresolved gaps:</span>
<span style="color:red">1. Feature misalignment: Traditional detectors lack attributes that capture prompt semantics, token dynamics, or API session behavior, resulting in zero recall on AI-specific attacks.</span>
<span style="color:red">2. Latency trade-offs: High-accuracy deep learning models sacrifice responsiveness, whereas fast models neglect the nuanced patterns of inference abuse.</span>
<span style="color:red">3. Evaluation shortcomings: No public benchmarks exist for AI phishing datasets, preventing reproducible comparisons or realistic performance claims.</span>
<span style="color:red">4. Adaptive adversaries: Generative models empower attackers to iterate quickly, yet few defenses incorporate continuous learning or adversarial testing loops.</span>

<span style="color:red">These gaps motivate the praxis objectives: engineer AI-aware features, build ensembles that balance accuracy and latency, curate reproducible datasets grounded in policy-compliant labeling, and design evaluation protocols that incorporate adaptive testing. Chapter 3 links each gap to a methodological response.</span>

## 2.7 Summary and Research Positioning
<span style="color:red">The literature confirms that phishing detection is a mature field for web and email contexts, but it has not addressed inference APIs where structured prompts, rapid automation, and metered compute redefine attack surfaces. Adversarial ML research validates the feasibility of model extraction and prompt manipulation yet stops short of delivering actionable detection frameworks. Latency studies emphasize the need for sub-two-hundred-millisecond defenses, and governance frameworks offer labeling standards that can be repurposed for AI-specific scenarios. By integrating these strands, the praxis positions itself as the first comprehensive effort to deliver an inference-aware phishing detector that aligns with production performance constraints and established security protocols.</span>
